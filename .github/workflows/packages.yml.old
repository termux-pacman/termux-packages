name: Packages

on:
  push:
    branches:
    - master
    paths:
    - 'packages/**'
  pull_request:
    paths:
    - 'packages/**'
  workflow_dispatch:
    inputs:
      packages:
        description: "A space-separated names of packages selected for rebuilding"
        required: true

jobs:
  build:
    runs-on: ubuntu-latest
    env:
      ANDROID_HOME: "/opt/termux/android-sdk"
      NDK: "/opt/termux/android-ndk"
    strategy:
      matrix:
        target_arch: [aarch64, arm, i686, x86_64]
      fail-fast: false
    steps:
    - name: Clone repository
      uses: actions/checkout@v2
      with:
        fetch-depth: 1000
    - name: Build
      run: |
        if [ "${{ github.event_name }}" != "workflow_dispatch" ]; then
          BASE_COMMIT=$(jq --raw-output .pull_request.base.sha "$GITHUB_EVENT_PATH")
          OLD_COMMIT=$(jq --raw-output .commits[0].id "$GITHUB_EVENT_PATH")
          HEAD_COMMIT=$(jq --raw-output .commits[-1].id "$GITHUB_EVENT_PATH")
          if [ "$BASE_COMMIT" = "null" ]; then
            if [ "$OLD_COMMIT" = "$HEAD_COMMIT" ]; then
              # Single-commit push.
              echo "Processing commit: ${HEAD_COMMIT}"
              CHANGED_FILES=$(git diff-tree --no-commit-id --name-only -r "${HEAD_COMMIT}")
            else
              # Multi-commit push.
              OLD_COMMIT="${OLD_COMMIT}~1"
              echo "Processing commit range: ${OLD_COMMIT}..${HEAD_COMMIT}"
              CHANGED_FILES=$(git diff-tree --no-commit-id --name-only -r "${OLD_COMMIT}" "${HEAD_COMMIT}")
            fi
          else
            # Pull requests.
            echo "Processing pull request #$(jq --raw-output .pull_request.number "$GITHUB_EVENT_PATH"): ${BASE_COMMIT}..HEAD"
            CHANGED_FILES=$(git diff-tree --no-commit-id --name-only -r "${BASE_COMMIT}" "HEAD")
          fi
        fi
        mkdir -p ./artifacts ./output
        touch ./output/.placeholder
        if [ "${{ github.event_name }}" != "workflow_dispatch" ]; then
          # Process tag '%ci:no-build' that may be added as line to commit message.
          # Forces CI to cancel current build with status 'passed'.
          if grep -qiP '^\s*%ci:no-build\s*$' <(git log --format="%B" -n 1 "HEAD"); then
            tar cf artifacts/output-${{ matrix.target_arch }}.tar output
            echo "[!] Force exiting as tag '%ci:no-build' was applied to HEAD commit message."
            exit 0
          fi
          # Build local Docker image if setup scripts were changed.
          # Useful for pull requests submitting changes for both build environment and packages.
          if grep -qP '^scripts/(Dockerfile|setup-ubuntu\.sh)$' <<< "$CHANGED_FILES"; then
            echo "Detected changes for environment setup scripts. Building custom Docker image now."
            cd ./scripts
            docker build -t termux/package-builder:latest .
            cd ..
          fi
          # Parse changed files and identify new packages and deleted packages.
          # Create lists of those packages that will be passed to upload job for
          # further processing.
          while read -r file; do
            if ! [[ $file == packages/* ]]; then
              # This file does not belong to a package, so ignore it
              continue
            fi
            if [[ $file =~ ^packages/([.a-z0-9+-]*)/([.a-z0-9+-]*).subpackage.sh$ ]]; then
              # A subpackage was modified, check if it was deleted or just updated
              pkg=${BASH_REMATCH[1]}
              subpkg=${BASH_REMATCH[2]}
              if [ ! -f "packages/${pkg}/${subpkg}.subpackage.sh" ]; then
                echo "$subpkg" >> ./deleted_packages.txt
              fi
            elif [[ $file =~ ^packages/([.a-z0-9+-]*)/.*$ ]]; then
              # package, check if it was deleted or updated
              pkg=${BASH_REMATCH[1]}
              if [ ! -d "packages/${pkg}" ]; then
                echo "$pkg" >> ./deleted_packages.txt
              else
                echo "$pkg" >> ./built_packages.txt
                # If there are subpackages we want to create a list of those
                # as well
                for file in $(find "packages/${pkg}/" -maxdepth 1 -type f -name \*.subpackage.sh | sort); do
                  echo "$(basename "${file%%.subpackage.sh}")" >> ./built_subpackages.txt
                done
              fi
            fi
          done<<<${CHANGED_FILES}
        else
          for pkg in ${{ github.event.inputs.packages }}; do
            echo "$pkg" >> ./built_packages.txt
            for subpkg in $(find "packages/${pkg}/" -maxdepth 1 -type f -name \*.subpackage.sh | sort); do
              echo "$(basename "${subpkg%%.subpackage.sh}")" >> ./built_subpackages.txt
            done
          done
        fi

        # Fix so that lists do not contain duplicates
        if [ -f ./built_packages.txt ]; then
          uniq ./built_packages.txt > ./built_packages.txt.tmp
          mv ./built_packages.txt.tmp ./built_packages.txt
        fi
        if [ -f ./built_subpackages.txt ]; then
          uniq ./built_subpackages.txt > ./built_subpackages.txt.tmp
          mv ./built_subpackages.txt.tmp ./built_subpackages.txt
        fi
        if [ -f ./deleted_packages.txt ]; then
          uniq ./deleted_packages.txt > ./deleted_packages.txt.tmp
          mv ./deleted_packages.txt.tmp ./deleted_packages.txt
        fi

        if grep -qP '^rust$' ./built_packages.txt ; then
          echo "Free additional disk space on host"
          sudo apt purge -yq $(dpkg -l | grep '^ii' | awk '{ print $2 }' | grep -P '(cabal-|dotnet-|ghc-|libmono|php)') \
            liblldb-6.0 libllvm6.0:amd64 mono-runtime-common monodoc-manual powershell ruby
          sudo apt autoremove -yq
          sudo rm -rf /opt/hostedtoolcache /usr/local /usr/share/dotnet /usr/share/swift
        fi

        if [ -f ./built_packages.txt ]; then
          ./scripts/lint-packages.sh $(cat ./built_packages.txt | awk '{print "packages/"$1"/build.sh"}')
          ./scripts/run-docker.sh ./build-package.sh --format pacman -I -a ${{ matrix.target_arch }} $(cat ./built_packages.txt)
        fi

        test -d ./termux-packages/output && mv ./termux-packages/output/* ./output/
        # Put package lists into directory with *.pkg.* files so they will be transferred to
        # upload job.
        test -f ./deleted_packages.txt && mv ./deleted_packages.txt ./output/
        # Files containing certain symbols (e.g. ":") will cause failure in actions/upload-artifact.
        # Archiving *.pkg.* files in a tarball to avoid issues with uploading.
        tar cf artifacts/output-${{ matrix.target_arch }}-${{ github.sha }}.tar output
    - name: Checksums for built *.pkg.* files
      run: |
        find output -type f -name "*.pkg.*" -exec sha256sum "{}" \; | sort -k2
    - name: Store *.pkg.* files
      uses: actions/upload-artifact@v2
      with:
        name: termux-packages-${{ matrix.target_arch }}-${{ github.sha }}
        path: ./artifacts

  upload:
    if: github.event_name != 'pull_request'
    needs: build
    runs-on: ubuntu-18.04
    continue-on-error: true
    steps:
    - name: Clone repository
      uses: actions/checkout@v2
      with:
        persist-credentials: false
        fetch-depth: 0
    - name: Install aws
      uses: chrislennon/action-aws-cli@v1.1
    - name: Get *.pkg.* files
      uses: actions/download-artifact@v2
      with:
        path: ./
    - name: Uploading packages to hosting
      run: |
        for archive in termux-packages-*/*.tar; do
          dir_sp=(${archive//// })
          file_sp=(${dir_sp[-1]//-/ })
          dir=output/${file_sp[1]}
          mkdir -p $dir
          tar xf "$archive" -C $dir
        done
        aws s3 cp ./output s3://termux-main.pacman/ --recursive
      env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
